{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>__Data__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>brightness</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_t31</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.8070</td>\n",
       "      <td>142.0583</td>\n",
       "      <td>313.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>56</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>48</td>\n",
       "      <td>6.3</td>\n",
       "      <td>297.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.7924</td>\n",
       "      <td>142.0850</td>\n",
       "      <td>319.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>56</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>71</td>\n",
       "      <td>6.3</td>\n",
       "      <td>297.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.8398</td>\n",
       "      <td>132.8744</td>\n",
       "      <td>311.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>42</td>\n",
       "      <td>6.3</td>\n",
       "      <td>298.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14.4306</td>\n",
       "      <td>143.3035</td>\n",
       "      <td>310.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>33</td>\n",
       "      <td>6.3</td>\n",
       "      <td>296.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.4953</td>\n",
       "      <td>131.4897</td>\n",
       "      <td>310.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>36</td>\n",
       "      <td>6.3</td>\n",
       "      <td>298.8</td>\n",
       "      <td>27.6</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  brightness  scan  track    acq_date  acq_time  \\\n",
       "0  -11.8070   142.0583       313.0   1.0    1.0  2019-08-01        56   \n",
       "1  -11.7924   142.0850       319.3   1.0    1.0  2019-08-01        56   \n",
       "2  -12.8398   132.8744       311.6   3.1    1.7  2019-08-01        57   \n",
       "3  -14.4306   143.3035       310.1   1.1    1.1  2019-08-01        57   \n",
       "4  -12.4953   131.4897       310.3   4.0    1.9  2019-08-01        57   \n",
       "\n",
       "  satellite instrument  confidence  version  bright_t31   frp daynight  type  \n",
       "0     Terra      MODIS          48      6.3       297.3   6.6        D     0  \n",
       "1     Terra      MODIS          71      6.3       297.3  11.3        D     0  \n",
       "2     Terra      MODIS          42      6.3       298.7  23.1        D     0  \n",
       "3     Terra      MODIS          33      6.3       296.1   6.5        D     0  \n",
       "4     Terra      MODIS          36      6.3       298.8  27.6        D     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/PythonFile/DataAnalysis/data/AustraliaFire/fire_archive_M6_96619.csv\")\n",
    "\n",
    "test = df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  构造位置json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "{'2019-08-22', '2019-08-03', '2019-09-27', '2019-09-02', '2019-08-28', '2019-09-18', '2019-08-09', '2019-09-21', '2019-08-10', '2019-09-04', '2019-08-30', '2019-08-12', '2019-08-21', '2019-08-27', '2019-09-29', '2019-09-08', '2019-08-29', '2019-08-14', '2019-09-16', '2019-09-20', '2019-09-17', '2019-08-31', '2019-08-08', '2019-08-02', '2019-08-23', '2019-09-11', '2019-09-06', '2019-09-22', '2019-09-14', '2019-09-28', '2019-09-07', '2019-09-15', '2019-08-07', '2019-09-23', '2019-09-03', '2019-08-04', '2019-08-15', '2019-09-13', '2019-08-16', '2019-09-30', '2019-08-13', '2019-09-10', '2019-09-25', '2019-08-26', '2019-09-05', '2019-08-18', '2019-08-01', '2019-09-19', '2019-09-26', '2019-08-20', '2019-09-01', '2019-08-11', '2019-09-12', '2019-08-24', '2019-08-25', '2019-09-09', '2019-08-05', '2019-08-17', '2019-08-06', '2019-09-24', '2019-08-19'}\n"
     ]
    }
   ],
   "source": [
    "# 统计表格天数\n",
    "days = set()\n",
    "for d in df['acq_date']:\n",
    "    days.add(d)\n",
    "\n",
    "print(len(days))\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_08_22 success\n",
      "2019_08_22 success\n",
      "2019_08_03 success\n",
      "2019_08_03 success\n",
      "2019_09_27 success\n",
      "2019_09_27 success\n",
      "2019_09_02 success\n",
      "2019_09_02 success\n",
      "2019_08_28 success\n",
      "2019_08_28 success\n",
      "2019_09_18 success\n",
      "2019_09_18 success\n",
      "2019_08_09 success\n",
      "2019_08_09 success\n",
      "2019_09_21 success\n",
      "2019_09_21 success\n",
      "2019_08_10 success\n",
      "2019_08_10 success\n",
      "2019_09_04 success\n",
      "2019_09_04 success\n",
      "2019_08_30 success\n",
      "2019_08_30 success\n",
      "2019_08_12 success\n",
      "2019_08_12 success\n",
      "2019_08_21 success\n",
      "2019_08_21 success\n",
      "2019_08_27 success\n",
      "2019_08_27 success\n",
      "2019_09_29 success\n",
      "2019_09_29 success\n",
      "2019_09_08 success\n",
      "2019_09_08 success\n",
      "2019_08_29 success\n",
      "2019_08_29 success\n",
      "2019_08_14 success\n",
      "2019_08_14 success\n",
      "2019_09_16 success\n",
      "2019_09_16 success\n",
      "2019_09_20 success\n",
      "2019_09_20 success\n",
      "2019_09_17 success\n",
      "2019_09_17 success\n",
      "2019_08_31 success\n",
      "2019_08_31 success\n",
      "2019_08_08 success\n",
      "2019_08_08 success\n",
      "2019_08_02 success\n",
      "2019_08_02 success\n",
      "2019_08_23 success\n",
      "2019_08_23 success\n",
      "2019_09_11 success\n",
      "2019_09_11 success\n",
      "2019_09_06 success\n",
      "2019_09_06 success\n",
      "2019_09_22 success\n",
      "2019_09_22 success\n",
      "2019_09_14 success\n",
      "2019_09_14 success\n",
      "2019_09_28 success\n",
      "2019_09_28 success\n",
      "2019_09_07 success\n",
      "2019_09_07 success\n",
      "2019_09_15 success\n",
      "2019_09_15 success\n",
      "2019_08_07 success\n",
      "2019_08_07 success\n",
      "2019_09_23 success\n",
      "2019_09_23 success\n",
      "2019_09_03 success\n",
      "2019_09_03 success\n",
      "2019_08_04 success\n",
      "2019_08_04 success\n",
      "2019_08_15 success\n",
      "2019_08_15 success\n",
      "2019_09_13 success\n",
      "2019_09_13 success\n",
      "2019_08_16 success\n",
      "2019_08_16 success\n",
      "2019_09_30 success\n",
      "2019_09_30 success\n",
      "2019_08_13 success\n",
      "2019_08_13 success\n",
      "2019_09_10 success\n",
      "2019_09_10 success\n",
      "2019_09_25 success\n",
      "2019_09_25 success\n",
      "2019_08_26 success\n",
      "2019_08_26 success\n",
      "2019_09_05 success\n",
      "2019_09_05 success\n",
      "2019_08_18 success\n",
      "2019_08_18 success\n",
      "2019_08_01 success\n",
      "2019_08_01 success\n",
      "2019_09_19 success\n",
      "2019_09_19 success\n",
      "2019_09_26 success\n",
      "2019_09_26 success\n",
      "2019_08_20 success\n",
      "2019_08_20 success\n",
      "2019_09_01 success\n",
      "2019_09_01 success\n",
      "2019_08_11 success\n",
      "2019_08_11 success\n",
      "2019_09_12 success\n",
      "2019_09_12 success\n",
      "2019_08_24 success\n",
      "2019_08_24 success\n",
      "2019_08_25 success\n",
      "2019_08_25 success\n",
      "2019_09_09 success\n",
      "2019_09_09 success\n",
      "2019_08_05 success\n",
      "2019_08_05 success\n",
      "2019_08_17 success\n",
      "2019_08_17 success\n",
      "2019_08_06 success\n",
      "2019_08_06 success\n",
      "2019_09_24 success\n",
      "2019_09_24 success\n",
      "2019_08_19 success\n",
      "2019_08_19 success\n"
     ]
    }
   ],
   "source": [
    "# 按天、白天晚上读取起火点位置的经纬度\n",
    "for d in days:\n",
    "    day = df[df['acq_date'] == d]\n",
    "    \n",
    "    day_d = day[day['daynight'] == \"D\"]\n",
    "    day_n = day[day['daynight'] == \"N\"]\n",
    "    \n",
    "#   读取白天的位置经纬度\n",
    "    try:\n",
    "        data_d = {}\n",
    "        for i in range(day_d.index[0],day_d.index[-1]+1):\n",
    "            try:\n",
    "                data_d[\"Fire_{}\".format(i)] = [day_d['longitude'][i],day_d['latitude'][i]]\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        with open(\"day_{}_d.json\".format(d.replace('-',\"_\")),'w') as f:\n",
    "            json.dump(data_d,f)\n",
    "            print(\"{} success\".format(d.replace(\"-\",'_')))\n",
    "    except:\n",
    "        print('{} D数据 failure'.format(d))\n",
    "    \n",
    "#   读取黑夜的位置经纬度\n",
    "    try:\n",
    "        data_n = {}\n",
    "        for i in range(day_n.index[0],day_n.index[-1]+1):\n",
    "            data_n[\"Fire_{}\".format(i)] = [day_n['longitude'][i],day_n['latitude'][i]]\n",
    "        \n",
    "        with open(\"day_{}_n.json\".format(d.replace('-',\"_\")),'w')as f:\n",
    "            json.dump(data_n,f)\n",
    "            print(\"{} success\".format(d.replace(\"-\",'_')))\n",
    "    except:\n",
    "        print('{} N数据 failure'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>__Pyecharts__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Geo\n",
    "from pyecharts.faker import Faker \n",
    "from pyecharts.globals import ChartType\n",
    "\n",
    "from pyecharts.datasets import COORDINATES\n",
    "COORDINATES.cutoff = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = \"d:/pythonfile/dataanalysis/australia_fire/\"\n",
    "filelist = listdir(path)\n",
    "\n",
    "for f in filelist:\n",
    "    loc_d = []\n",
    "    loc_n = []\n",
    "    if f[-6:] == 'd.json':\n",
    "        loc = open(path+f)\n",
    "        data = json.load(loc)\n",
    "        for k in data:\n",
    "            loc_d.append(k)\n",
    "        c = (geo()\n",
    "            .add_schema(\"澳大利亚\")\n",
    "            .add_coordinate(f)\n",
    "            .add(\"day\",[list(z) for z in zip(loc_d,count)],'scatter')\n",
    "             \n",
    "            .set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "            .ser_globel_opts(title_opts.opts.TitleOpts(title=\"Fire plot\"))\n",
    "             \n",
    "             .render(\"{}.html\".format(f[0:]))\n",
    "            )\n",
    "        \n",
    "    if f[-6:] == 'n.json':\n",
    "        loc = open(path+f)\n",
    "        data = json.load(loc)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-ae3e2653c3e9>:1: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='d:/pythonfile/dataanalysis/australia_fire/day_2019_08_01_d.json' mode='r' encoding='cp936'>\n",
      "\n",
      "<ipython-input-114-ae3e2653c3e9>:4: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='d:/pythonfile/dataanalysis/australia_fire/day_2019_08_01_n.json' mode='r' encoding='cp936'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc_d = open(\"d:/pythonfile/dataanalysis/australia_fire/day_2019_08_01_d.json\")\n",
    "data = json.load(loc_d)\n",
    "\n",
    "loc_n = open('d:/pythonfile/dataanalysis/australia_fire/day_2019_08_01_n.json')\n",
    "data_n = json.load(loc_n)\n",
    "\n",
    "ls_d = []\n",
    "for k in data:\n",
    "    ls_d.append(k)\n",
    "    \n",
    "ls_n = []\n",
    "for k in data_n:\n",
    "    ls_n.append(k)\n",
    "\n",
    "count = []\n",
    "for i in range(0,420):\n",
    "    w = random.randint(10,1000)\n",
    "    count.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning:\n",
      "\n",
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "\n",
      "d:\\anaconda\\lib\\asyncio\\events.py:81: DeprecationWarning:\n",
      "\n",
      "`run_cell_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "\n",
      "d:\\anaconda\\lib\\site-packages\\pyecharts\\charts\\chart.py:14: PendingDeprecationWarning:\n",
      "\n",
      "pyecharts 所有图表类型将在 v1.9.0 版本开始强制使用 ChartItem 进行数据项配置 :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c =( Geo()\n",
    "    .add_schema(maptype='澳大利亚')\n",
    "    .add_coordinate_json(\"day_2019_08_01_d.json\")\n",
    "    .add_coordinate_json(\"day_2019_08_01_n.json\")\n",
    "    .add(\"day\",[list(z) for z in zip(ls_d,count)],\"effectScatter\")\n",
    "    .add(\"night\",[list(z) for z in zip(ls_n,count)],'scatter')\n",
    "    \n",
    "    .set_series_opts(label_opts=opts.LabelOpts(is_show=True))\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"Geo\"))\n",
    "    .render(\"2019_0801.html\")\n",
    "   )\n",
    "\n",
    "# c.render_notebook()\n",
    "print(\"successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
